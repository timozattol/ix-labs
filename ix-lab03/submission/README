Since your thesis rotates around random graphs, you decide to apply your amazing algorithm
on a instance of a random graph G(n, p). You generate a G(n, p), and you remove uniformly at
random some edges. What would be the performance of your algorithm on predicting these missing
edges? What is the best strategy for finding these missing links? Justify rigorously your answer
(and think before coding ^¨ )


- Same as random, or worse. It not mathematically possible to predict something totally random. 
Each edge has the exact same probability of being removed, so it's the same as asking someone to predict the outcome of a fair die.

=Facebook social network=

1. Setting N = 10 000 and node u as initial seed, what is the average age of a Facebook user?

- By simply computing sumAges / N, we get 46.42

2. A study whose title is “Facebook, by Facebook” is released, and it reveals that the average
age of Facebook’s users is 52.6 years old. How close is you estimation to the true average
age? How do you explain it?

- Our estimate is about 10% off. The random walk is unfair, because it traverses more often vertices with high degrees than 
vertices with low degree. Young people probably have more friends (higher degree) on average 
than older people, thus bringing down the average age.  

3. What would you change in your crawler in order to have a more accurate estimate of average
age? You solution should require neither additional seeds nor more memory allocated.

- We take the degree of each node into account, thus compensating for the popularity bias.

=Bizarre social networks=

1. Setting N = 10 000, what is the average age of Ages’s users when you start your crawl from
node u? from node v? from node w? Can you explain which properties of the network could
cause this?

-u : 63.64 
-v : 82.58
-w : 60.77

- There is probably a component that is very weakly connected to other components, 
and v is in this "lonely component".

2. What would you change in your crawler in order to have a more accurate estimate of average
age? Hint: Starting your crawler from node u, increase N and observe the impact on the age
estimate.

- (We think the question has a typo and speaks about node v, not u)
- We increased N to 10x the old value and now the average went down to 70.42, meaning that after a great number of iterations, the random walk was able to get out of the lonely component.

Finally, you want to crawl yet another social network called Directions (whose average user
is, we heard, 32.5 years old.) Complete the code in DirectionsSampling. What estimate of the
average age of Directions’s users do you get when you start your crawl from node u? From
node v? From node w? Explain what you obtain.

-u : 49.47
-v : 49.48
-w : 49.51

- Unfortunately, it's worse than with AgeSampling because here it looks like u, v and w are all three in the same "lonely" component.