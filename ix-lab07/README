1
Spend some time inspecting the raw data. Are you able to find your favorite movie in? What
languages are the plots written in?
=> Favorite movie found, plots written in English.

2.2
 For starters, try to search for “James Bond 007”. What
do you think of the results? Try out different queries
=> Works very well, we also tried Lord of the rings, almost all the results are related to the search.

For James Bond 007:
01. Dr. No (1962) (score: 0.97655)
02. James Bond: Shaken and Stirred (1997) (TV) (score: 0.93868)
03. Casino Royale (1967) (score: 0.88774)
04. The World Is Not Enough (1999) (score: 0.76798)
05. The Living Daylights (1987) (score: 0.74025)
06. Die Another Day (2002) (score: 0.73592)
07. The Making of 'The World Is Not Enough' (1999) (V) (score: 0.70328)
08. Zero Posterity (2006) (V) (score: 0.68285)
09. On Her Majesty's Secret Service (1969) (score: 0.68193)
10. Licence to Kill (1989) (score: 0.66520)
11. True Bond (2007) (TV) (score: 0.66456)
12. The Goldfinger Phenomenon (1995) (V) (score: 0.66218)
13. James Bond: Licence to Thrill (1987) (TV) (score: 0.64977)
14. Ian Fleming on Desert Island Discs (2006) (V) (score: 0.64037)
15. Never Say Never Again (1983) (score: 0.63990)
16. Donna James & Gary (2006) (score: 0.62717)
17. Tomorrow Never Dies (1997) (score: 0.61642)
18. The Last Call (2012/I) (score: 0.61544)
19. Live and Let Die (1973) (score: 0.61257)
20. La faute des autres (1923) (score: 0.59509)

What movies do you get back when you use this description as a
query string? Can you explain why “Babe (1981)” has such a high ranking?
=> 
01. Paintbrush (2008) (score: 1.12490)
02. Babe (1981) (score: 0.97120)
03. Have I Shared Too Much? (2011) (score: 0.96333)
04. Eu Odeio o Orkut (2011) (score: 0.82655)
05. I Love Alaska (2009) (score: 0.81054)

The only common word is "modeling", this is strange. After searching for "modeling",
Babe is third. Maybe it's one of the only film that contains this word in its 
description, and thus "modeling" has a big tf-idf, boosting the cosine-similarity 
between the ix description and Babe.

3.1
We already coded this for you, simply run TermDocumentMatrix
on the cluster. How many rows and columns does the matrix have?
=> 196848 (n of movies) = columns
    ? (n of different terms) = rows
The matrix is binary, we then tried "hadoop fs -text term-doc-matrix/* | wc -l"
to count the number of lines in every part-r-xxx, which gives:
161514

Run the Concepts command on the cluster to get a feel of the concepts behind the first
few dimensions uncovered by the transformation. The first dimension is particularly striking.
How can you explain what you see?
=> Yes, the first dimension seems to classify terms as "common" or not. Words that appear in many descriptions have high value, words that appear in one of few descriptions have low value.
Dimension 2 seems to separates "art" <--> "violence"
Others are not very obvious

First dimension:
-- dimension 1 - terms with lowest values:
suspi onstrat standabl celebra martoni gler licli canniti lectual horri cion cial nazzaro pointment antiqui enc benefi boarderless sadduce trutelink korteboldt lambertikirch kerkerinck prescib prinzipalmarkt aquina osnabruck 1530s liebenberg peddlar bienmann broissard villagairosa sherdeman 29s gainsvil ungrac unboyish vassilova nomic pathless rangnagar contraven pampanito moveabl hooverbal ionicu b58lcu stanfordvil 64400 

-- dimension 1 - terms with highest values:
follow want first back wife how help while own where mother go meet us home wai peopl show t becom come you through work old woman father dai make time girl take what them friend two world year new famili get stori live young find love man film life him 



LSISearch. Run some queries and compare the results
to those obtained using the vector space model. What do you think of the results? Are they
better, worse? Can you get an intuition about what’s happening?
=> They are worse when we search for few words, and ok ish for a full description of a movie.
This is logical because searching for literally james bond will only get other james bond movies, 
whereas searching for the plot of james bond will give other action/thrillers when looking at concepts.

James Bond 007:
01. True Bond (2007) (TV) (score: 0.34947)
02. The Last Call (2012/I) (score: 0.33277)
03. La faute des autres (1923) (score: 0.33029)
04. Donna James & Gary (2006) (score: 0.32230)
05. A Boost of Love (2012) (score: 0.31848)
06. One Goal, One Hope (2010) (score: 0.31822)
07. Massa'ot James Be'eretz Hakodesh (2003) (score: 0.30906)
08. Down the Coast (2011) (score: 0.30686)
09. Above Suspicion (2000) (score: 0.30353)
10. On Her Majesty's Secret Service (1969) (score: 0.29841)
11. Resonance (2011) (score: 0.29829)
12. James Bond: Shaken and Stirred (1997) (TV) (score: 0.29609)
13. Casino Royale (1967) (score: 0.29152)
14. James Bond: Licence to Thrill (1987) (TV) (score: 0.28864)
15. Beyond Loch Ness (2008) (TV) (score: 0.28769)
16. Crystal Jam (2010) (score: 0.28709)
17. On/Off (2003) (score: 0.28609)
18. Protege (2009) (score: 0.28378)
19. James (2008) (score: 0.28241)
20. Someday This Pain Will Be Useful to You (2011) (score: 0.27679)



4
In the folder data/review-sample you will find a small sample of 8 reviews. Can you
tell5 which ones are deceptive, and which ones are trutfhul? Do you identify features that
help you telling them apart?
=> "Reference to other hotels" make us think that the review is truthful. Also when very precise "stories" are
told, it seems truthful. On the other hand, when the person employs generic words as "much, very, many, etc." or
is being vague, the review seems deceptive. But honestly it's hard to tell.

4.2
Add Laplace smoothing to your classifier, and check the performance for varying prior count values
(try 0.1, 1.0, 10.0) What accuracy can you reach?
=> No laplace smoothing: 59%, Laplace smoothing: 0.1 = 1.0 => 86%, 10.0 => 78%.

4.3
Can you write such a review? Use the class Filter to test your attempts. Suppose that you
are given access to the parameters of the classifier, can you come up with a principled approach to
craft a review that will be classified as truthful?
=> 
